{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPACER Quick Start Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from model.dataset import BagsDataset, custom_collate_fn\n",
    "from model.model import MIL, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_all_genes(reference_gene_file):\n",
    "    all_genes = pd.read_csv(reference_gene_file)\n",
    "    return all_genes['Gene'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your interested geneset, in this study we use all human/mouse genes as our reference geneset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1orf141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PKP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HIVEP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SLC44A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23177</th>\n",
       "      <td>EPCAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23178</th>\n",
       "      <td>CEACAM21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23179</th>\n",
       "      <td>CEACAM6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23180</th>\n",
       "      <td>KRT8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23181</th>\n",
       "      <td>MAGE10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23182 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gene\n",
       "0      C1orf141\n",
       "1          PKP1\n",
       "2        HIVEP3\n",
       "3          GLMN\n",
       "4       SLC44A5\n",
       "...         ...\n",
       "23177     EPCAM\n",
       "23178  CEACAM21\n",
       "23179   CEACAM6\n",
       "23180      KRT8\n",
       "23181    MAGE10\n",
       "\n",
       "[23182 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define your interested geneset, in this study we use all human/mouse genes as our reference geneset\n",
    "all_genes = pd.read_csv('data/human_filtered.csv')\n",
    "all_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = all_genes['Gene'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immune cell: T\n",
      "[1 0 2]\n",
      "Tumor cells shape after filtering: (172613, 18085)\n",
      "Selecting top 3000 genes based on mean expression\n",
      "Preprocessed data: (334914, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Bags with radius 50: 100%|███████████████████████| 334914/334914 [03:27<00:00, 1613.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches created: 6612\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and create DataLoader(details data structure in data preparation section)\n",
    "adata = sc.read_h5ad('/work/OSPH/s439765/data4spacer/spatial_transcriptomics/VisiumHD/processed/Colon_Cancer_P2T_cell.h5ad')\n",
    "dataset = BagsDataset(\n",
    "    adata,\n",
    "    immune_cell='tcell',\n",
    "    radius=50,\n",
    "    max_instances=500,\n",
    "    n_genes=3000,\n",
    "    resolution='high',\n",
    "    k=2,  # Ensure 'k' matches the number of bags per batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want run the model for multiple data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adata</th>\n",
       "      <th>radius</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/project/shared/cli_wang/spatial_TCR/data/trai...</td>\n",
       "      <td>150</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/project/shared/cli_wang/spatial_TCR/data/trai...</td>\n",
       "      <td>150</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/project/shared/cli_wang/spatial_TCR/data/trai...</td>\n",
       "      <td>150</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/project/shared/cli_wang/spatial_TCR/data/trai...</td>\n",
       "      <td>150</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               adata  radius resolution\n",
       "0  /project/shared/cli_wang/spatial_TCR/data/trai...     150        low\n",
       "1  /project/shared/cli_wang/spatial_TCR/data/trai...     150        low\n",
       "2  /project/shared/cli_wang/spatial_TCR/data/trai...     150        low\n",
       "3  /project/shared/cli_wang/spatial_TCR/data/trai...     150        low"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas = pd.read_csv('data/sample.csv')\n",
    "adatas #make sure you have same data structure as in sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immune cell: T\n",
      "Reading adata from /project/shared/cli_wang/spatial_TCR/data/train_validate/Visium/HumanOvarianCancer/T_cell.h5ad\n",
      "['0', '1']\n",
      "Categories (2, object): ['0', '1']\n",
      "Tumor cells shape after filtering: (1226, 17943)\n",
      "Selecting top 3000 genes based on mean expression\n",
      "Percentile value: 4.840213894844055\n",
      "adata.obs[T] after binarization: AAACAAGTATCTCCCA-1    0\n",
      "AAACAATCTACTAGCA-1    0\n",
      "AAACACCAATAACTGC-1    0\n",
      "AAACAGAGCGACTCCT-1    0\n",
      "AAACAGCTTTCAGAAG-1    0\n",
      "Name: T, dtype: int64\n",
      "Processing: adata=T_cell.h5ad, radius=150, resolution=low\n",
      "Reading adata from /project/shared/cli_wang/spatial_TCR/data/train_validate/Visium/HumanOvarianCancerWholeTranscriptome/T_cell.h5ad\n",
      "['1', '0']\n",
      "Categories (2, object): ['0', '1']\n",
      "Tumor cells shape after filtering: (3043, 36601)\n",
      "Selecting top 3000 genes based on mean expression\n",
      "Percentile value: 0.0\n",
      "adata.obs[T] after binarization: AAACAAGTATCTCCCA-1    0\n",
      "AAACACCAATAACTGC-1    1\n",
      "AAACAGGGTCTATATT-1    0\n",
      "AAACATTTCCCGGATT-1    0\n",
      "AAACCCGAACGAAATC-1    0\n",
      "Name: T, dtype: int64\n",
      "Processing: adata=T_cell.h5ad, radius=150, resolution=low\n",
      "Reading adata from /project/shared/cli_wang/spatial_TCR/data/train_validate/Visium/HumanColorectalCancerWholeTranscriptome/T_cell.h5ad\n",
      "['0', '1']\n",
      "Categories (2, object): ['0', '1']\n",
      "Tumor cells shape after filtering: (2026, 36601)\n",
      "Selecting top 3000 genes based on mean expression\n",
      "Percentile value: 0.6254532486200333\n",
      "adata.obs[T] after binarization: AAACAAGTATCTCCCA-1    0\n",
      "AAACAATCTACTAGCA-1    0\n",
      "AAACAGAGCGACTCCT-1    0\n",
      "AAACCCGAACGAAATC-1    0\n",
      "AAACCGGGTAGGTACC-1    0\n",
      "Name: T, dtype: int64\n",
      "Processing: adata=T_cell.h5ad, radius=150, resolution=low\n",
      "Reading adata from /project/shared/cli_wang/spatial_TCR/data/train_validate/Visium/HumanOvarianCancerFFPE/T_cell.h5ad\n",
      "['1', '0']\n",
      "Categories (2, object): ['0', '1']\n",
      "Tumor cells shape after filtering: (3667, 18085)\n",
      "Selecting top 3000 genes based on mean expression\n",
      "Percentile value: 0.6455146968364716\n",
      "adata.obs[T] after binarization: AACAATGTGCTCCGAG-1    0\n",
      "AACACCATTCGCATAC-1    0\n",
      "AACACGTTGATACCGC-1    1\n",
      "AACACTCGTGAGCTTC-1    0\n",
      "AACAGCCTCCTGACTA-1    0\n",
      "Name: T, dtype: int64\n",
      "Processing: adata=T_cell.h5ad, radius=150, resolution=low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Bags with radius 150: 100%|█████████████████████████| 3455/3455 [00:00<00:00, 19170.34it/s]\n",
      "Creating Bags with radius 150: 100%|██████████████████████████| 3491/3491 [00:00<00:00, 8365.62it/s]\n",
      "Creating Bags with radius 150: 100%|█████████████████████████| 3138/3138 [00:00<00:00, 12010.87it/s]\n",
      "Creating Bags with radius 150: 100%|██████████████████████████| 4671/4671 [00:00<00:00, 8497.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches created: 2354\n"
     ]
    }
   ],
   "source": [
    "dataset = BagsDataset(\n",
    "    'data/sample.csv',\n",
    "    immune_cell='tcell',\n",
    "    max_instances=500,\n",
    "    n_genes=3000,\n",
    "    k=2,  # Ensure 'k' matches the number of bags per batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"Using device: {device} ({torch.cuda.get_device_name(torch.cuda.current_device())})\")\n",
    "else:\n",
    "    print(f\"Using device: {device}\")\n",
    "print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MIL(all_genes).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.02)\n",
    "early_stopping = EarlyStopping(patience=5, delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'sample_output'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_model_path = os.path.join(output_dir, 'best_model.pth')\n",
    "\n",
    "# Save spacer scores before training\n",
    "spacer_scores_before_training = model.immunogenicity.ig.clone().detach().cpu()\n",
    "spacer_scores_before_training = [score.item() for score in spacer_scores_before_training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(epoch, train_loss, val_loss, val_auroc, a, b, alpha, beta, output_dir):\n",
    "    file_path = os.path.join(output_dir, 'training_metrics.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create the CSV file with headers\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write('Epoch,Train Loss,Val Loss,Val AUROC,a,b,alpha,beta\\n')\n",
    "    \n",
    "    # Append metrics for the current epoch\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(f'{epoch},{train_loss},{val_loss},{val_auroc},{a},{b},{alpha},{beta}\\n')\n",
    "\n",
    "def save_spacer_scores(epoch, all_genes, spacer_scores_before_training, spacer_scores_after_training, output_dir):\n",
    "    # Create a DataFrame with IG scores before and after the current epoch\n",
    "    spacer_score_data = {\n",
    "        'Gene': all_genes,\n",
    "        'SPACER Score Before Training': spacer_scores_before_training,\n",
    "        'SPACER Score After Training': spacer_scores_after_training,\n",
    "    }\n",
    "    df = pd.DataFrame(spacer_score_data)\n",
    "    \n",
    "    # Calculate the difference and add it as a new column\n",
    "    df['Difference'] = df['SPACER Score After Training'] - df['SPACER Score Before Training']\n",
    "    df = df.sort_values(by='Difference', ascending=False)\n",
    "\n",
    "    # Save to a CSV file for each epoch\n",
    "    output_path = os.path.join(output_dir, f'spacer_score_changes_epoch_{epoch+1}.csv')\n",
    "    df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "selection = 'negative' # Choose 'positive(induce)' or 'negative(repel)' based on your research focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 2118/2118 [00:12<00:00, 172.67batch/s, loss=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.6846, AUROC: 0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [00:01<00:00, 213.92batch/s, val_loss=0.519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6849, Validation AUROC: 0.5764\n",
      "Best model saved with validation loss 0.6849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 2118/2118 [00:12<00:00, 172.50batch/s, loss=0.587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 0.6830, AUROC: 0.5834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [00:00<00:00, 250.45batch/s, val_loss=0.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6848, Validation AUROC: 0.5816\n",
      "Best model saved with validation loss 0.6848\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "        \n",
    "    # Lists to store outputs and labels for AUROC calculation\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "        \n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for i, batch_data in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Unpack the batch data\n",
    "            distances_list, gene_expressions_list, labels_list, core_idxs_list, gene_names_list, cell_ids_list = batch_data\n",
    "                \n",
    "            # Move data to device and prepare labels\n",
    "            distances_list = [distances.to(device) for distances in distances_list]\n",
    "            gene_expressions_list = [gene_exp.to(device) for gene_exp in gene_expressions_list]\n",
    "            labels = torch.stack(labels_list).float().to(device)\n",
    "            current_genes_list = gene_names_list  # List of gene names for each bag\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(distances_list, gene_expressions_list, current_genes_list)\n",
    "                \n",
    "            if outputs is None:\n",
    "                 continue  # Skip this batch if the model returns None\n",
    "                \n",
    "            if outputs.shape[0] != labels.shape[0]:\n",
    "                # Handle mismatch in batch sizes if necessary\n",
    "                continue\n",
    "                \n",
    "            # Compute BCE loss\n",
    "            if selection == 'negative':\n",
    "                labels = 1 - labels\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "                \n",
    "            # Accumulate outputs and labels for AUROC calculation\n",
    "            all_outputs.extend(outputs.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "    # Compute Training AUROC\n",
    "    try:\n",
    "        epoch_auc = roc_auc_score(all_labels, all_outputs)\n",
    "    except ValueError:\n",
    "        epoch_auc = float('nan')  # Handle case where AUROC can't be computed\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, AUROC: {epoch_auc:.4f}')\n",
    "        \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_all_outputs = []\n",
    "    val_all_labels = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, unit=\"batch\") as vtepoch:\n",
    "            for val_batch_data in vtepoch:\n",
    "                # Unpack validation batch data\n",
    "                val_distances_list, val_gene_expressions_list, val_labels_list, val_core_idxs_list, val_gene_names_list, val_cell_ids_list = val_batch_data\n",
    "                    \n",
    "                # Move data to device and prepare labels\n",
    "                val_distances_list = [distances.to(device) for distances in val_distances_list]\n",
    "                val_gene_expressions_list = [gene_exp.to(device) for gene_exp in val_gene_expressions_list]\n",
    "                val_labels = torch.stack(val_labels_list).float().to(device)\n",
    "                val_current_genes_list = val_gene_names_list  # List of gene names for each bag\n",
    "                    \n",
    "                # Forward pass\n",
    "                val_outputs = model(val_distances_list, val_gene_expressions_list, val_current_genes_list)\n",
    "                    \n",
    "                if val_outputs is None:\n",
    "                    continue  # Skip this batch if the model returns None\n",
    "                    \n",
    "                if val_outputs.shape[0] != val_labels.shape[0]:\n",
    "                    # Handle mismatch in batch sizes if necessary\n",
    "                    continue\n",
    "                    \n",
    "                # Compute BCE loss\n",
    "                if selection == 'negative':\n",
    "                    val_labels = 1 - val_labels\n",
    "                loss = criterion(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "                vtepoch.set_postfix(val_loss=loss.item())\n",
    "                    \n",
    "                # Accumulate outputs and labels for AUROC calculation\n",
    "                val_all_outputs.extend(val_outputs.detach().cpu().numpy())\n",
    "                val_all_labels.extend(val_labels.cpu().numpy())\n",
    "            \n",
    "        val_loss /= len(val_loader)\n",
    "            \n",
    "            # Compute Validation AUROC\n",
    "        try:\n",
    "            val_epoch_auc = roc_auc_score(val_all_labels, val_all_outputs)\n",
    "        except ValueError:\n",
    "            val_epoch_auc = float('nan')  # Handle case where AUROC can't be computed\n",
    "            \n",
    "        print(f'Validation Loss: {val_loss:.4f}, Validation AUROC: {val_epoch_auc:.4f}')\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Best model saved with validation loss {val_loss:.4f}\")\n",
    "            \n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, f'model_epoch_{epoch+1}.pth'))\n",
    "        \n",
    "    a = model.distance.a.clone().detach().cpu().numpy()\n",
    "    b = model.gene_expression.b.clone().detach().cpu()\n",
    "    alpha = model.alpha.clone().detach().cpu()\n",
    "    beta = model.beta.clone().detach().cpu()\n",
    "    # Save metrics\n",
    "    save_metrics(epoch+1, train_loss, val_loss, val_epoch_auc,a,b,alpha,beta, output_dir)\n",
    "\n",
    "    # Save IG scores after each epoch\n",
    "    spacer_scores_after_training = model.immunogenicity.ig.clone().detach().cpu()\n",
    "    spacer_scores_after_training = [score.item() for score in spacer_scores_after_training]\n",
    "    save_spacer_scores(epoch, all_genes, spacer_scores_before_training, spacer_scores_after_training, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_tcr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
